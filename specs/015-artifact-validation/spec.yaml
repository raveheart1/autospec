feature:
  branch: "015-artifact-validation"
  created: "2025-12-15"
  status: "Draft"
  input: "Add 'autospec artifact [type] [path]' command that validates YAML artifacts against their schemas. Types: spec, plan, tasks. Validates: (1) valid YAML syntax, (2) required fields present for artifact type, (3) field types correct (strings, lists, enums), (4) cross-references valid (e.g. task dependencies exist). Output: success message with artifact summary OR detailed error with line numbers and hints. Add --schema flag to print expected schema for artifact type. Add --fix flag to auto-fix common issues (missing optional fields, formatting). Then update all .autospec/commands/autospec*.md slash command templates to call 'autospec artifact TYPE PATH' at the end of each phase to validate output before completing."

user_stories:
  - id: "US-001"
    title: "Validate spec artifact after generation"
    priority: "P1"
    as_a: "developer using autospec"
    i_want: "to validate my spec.yaml file against the schema after generation"
    so_that: "I can catch structural errors before proceeding to planning"
    why_this_priority: "Core validation ensures workflow artifacts are correct before downstream phases consume them"
    independent_test: "Run validation on valid and invalid spec.yaml files, verify correct pass/fail behavior"
    acceptance_scenarios:
      - given: "a properly structured spec.yaml file exists"
        when: "I run 'autospec artifact spec specs/015-feature/spec.yaml'"
        then: "I see a success message with summary (story count, requirement count)"
      - given: "a spec.yaml with missing required fields"
        when: "I run 'autospec artifact spec specs/015-feature/spec.yaml'"
        then: "I see detailed errors with line numbers and hints for each issue"

  - id: "US-002"
    title: "Validate plan artifact after generation"
    priority: "P1"
    as_a: "developer using autospec"
    i_want: "to validate my plan.yaml file against the schema after planning"
    so_that: "I can ensure the implementation plan is complete before task generation"
    why_this_priority: "Plan validation ensures tasks can be properly generated from a valid plan"
    independent_test: "Run validation on valid and invalid plan.yaml files, verify correct pass/fail behavior"
    acceptance_scenarios:
      - given: "a properly structured plan.yaml file exists"
        when: "I run 'autospec artifact plan specs/015-feature/plan.yaml'"
        then: "I see a success message with summary (phase count, component count)"
      - given: "a plan.yaml with invalid field types"
        when: "I run 'autospec artifact plan specs/015-feature/plan.yaml'"
        then: "I see errors indicating expected vs actual types with line numbers"

  - id: "US-003"
    title: "Validate tasks artifact after generation"
    priority: "P1"
    as_a: "developer using autospec"
    i_want: "to validate my tasks.yaml file against the schema after task generation"
    so_that: "I can verify task dependencies are valid before implementation"
    why_this_priority: "Task validation with cross-reference checking prevents blocked implementations"
    independent_test: "Run validation on tasks.yaml with valid and invalid dependency references"
    acceptance_scenarios:
      - given: "a tasks.yaml file with all dependencies pointing to existing tasks"
        when: "I run 'autospec artifact tasks specs/015-feature/tasks.yaml'"
        then: "I see a success message with summary (task count, completed count, pending count)"
      - given: "a tasks.yaml with a dependency referencing non-existent task ID"
        when: "I run 'autospec artifact tasks specs/015-feature/tasks.yaml'"
        then: "I see an error identifying the invalid reference with line number and suggestion"

  - id: "US-004"
    title: "View schema for artifact type"
    priority: "P2"
    as_a: "developer creating artifacts manually"
    i_want: "to view the expected schema for any artifact type"
    so_that: "I know what fields and structure are required"
    why_this_priority: "Schema visibility aids manual artifact creation and debugging"
    independent_test: "Run --schema flag for each artifact type, verify schema output is complete and readable"
    acceptance_scenarios:
      - given: "I want to understand the spec artifact structure"
        when: "I run 'autospec artifact spec --schema'"
        then: "I see the full spec schema with field names, types, and whether they are required"
      - given: "I want to understand the tasks artifact structure"
        when: "I run 'autospec artifact tasks --schema'"
        then: "I see the tasks schema including enum values for status fields"

  - id: "US-005"
    title: "Auto-fix common artifact issues"
    priority: "P2"
    as_a: "developer with a nearly-valid artifact"
    i_want: "to automatically fix common issues like missing optional fields"
    so_that: "I don't have to manually add boilerplate or fix formatting"
    why_this_priority: "Auto-fix reduces friction and speeds up the workflow"
    independent_test: "Run --fix on artifacts with fixable issues, verify corrections are applied"
    acceptance_scenarios:
      - given: "a spec.yaml missing optional metadata fields"
        when: "I run 'autospec artifact spec path/to/spec.yaml --fix'"
        then: "missing optional fields are added with default values and file is saved"
      - given: "a tasks.yaml with inconsistent YAML formatting"
        when: "I run 'autospec artifact tasks path/to/tasks.yaml --fix'"
        then: "formatting is normalized and file is saved"
      - given: "a spec.yaml with unfixable structural errors"
        when: "I run 'autospec artifact spec path/to/spec.yaml --fix'"
        then: "I see errors for unfixable issues with hints, fixable issues are still corrected"

  - id: "US-006"
    title: "Automatic validation in slash commands"
    priority: "P1"
    as_a: "developer running autospec workflows"
    i_want: "each phase's slash command to automatically validate its output"
    so_that: "I get immediate feedback if the generated artifact is malformed"
    why_this_priority: "Integrated validation ensures consistent artifact quality across all workflows"
    independent_test: "Run each slash command, verify validation is called at end of each phase"
    acceptance_scenarios:
      - given: "I run the /autospec.specify command"
        when: "the command completes generation"
        then: "it automatically runs 'autospec artifact spec' on the output before completing"
      - given: "I run the /autospec.plan command"
        when: "the command completes generation"
        then: "it automatically runs 'autospec artifact plan' on the output before completing"
      - given: "the generated artifact fails validation"
        when: "the validation runs at the end of a phase"
        then: "the error is displayed and the user can fix issues before proceeding"

  - id: "US-007"
    title: "Comprehensive test fixtures for validation development"
    priority: "P1"
    as_a: "developer working on validation code"
    i_want: "a library of test fixtures covering common YAML issues for each artifact type"
    so_that: "I can easily test validation logic against known-bad inputs without manual fixture creation"
    why_this_priority: "Test fixtures accelerate development and ensure comprehensive coverage of validation scenarios"
    independent_test: "Verify each fixture file exists, is parseable, and triggers its documented validation error"
    acceptance_scenarios:
      - given: "I need to test missing required field validation"
        when: "I look in internal/validation/testdata/"
        then: "I find fixture files for each artifact type with specific required fields removed"
      - given: "I need to test type mismatch validation"
        when: "I look in internal/validation/testdata/"
        then: "I find fixture files with wrong types (string where list expected, etc.)"
      - given: "I need to test cross-reference validation"
        when: "I look in internal/validation/testdata/"
        then: "I find tasks.yaml fixtures with invalid dependency references"
      - given: "I need to test valid artifacts"
        when: "I look in internal/validation/testdata/"
        then: "I find golden/valid fixture files for each artifact type that pass all validation"

requirements:
  functional:
    - id: "FR-001"
      description: "MUST accept artifact type as first argument (spec, plan, tasks)"
      testable: true
      acceptance_criteria: "Command accepts exactly these three types, rejects others with clear error"

    - id: "FR-002"
      description: "MUST accept file path as second argument"
      testable: true
      acceptance_criteria: "Command processes the specified file, shows clear error if file not found"

    - id: "FR-003"
      description: "MUST validate YAML syntax and report parsing errors with line numbers"
      testable: true
      acceptance_criteria: "Invalid YAML triggers error with exact line number and column if available"

    - id: "FR-004"
      description: "MUST validate presence of required fields for each artifact type"
      testable: true
      acceptance_criteria: "Missing required fields listed with their expected location in structure"

    - id: "FR-005"
      description: "MUST validate field types (strings, lists, enums, nested objects)"
      testable: true
      acceptance_criteria: "Type mismatches show expected vs actual type with field path"

    - id: "FR-006"
      description: "MUST validate cross-references (e.g., task dependency IDs exist)"
      testable: true
      acceptance_criteria: "Invalid references show the reference value and list valid options"

    - id: "FR-007"
      description: "MUST display success message with artifact summary on valid artifacts"
      testable: true
      acceptance_criteria: "Valid artifact shows type, key counts (stories, tasks, etc.), and pass confirmation"

    - id: "FR-008"
      description: "MUST display detailed errors with line numbers on invalid artifacts"
      testable: true
      acceptance_criteria: "Each error shows line number, field path, issue description, and hint if applicable"

    - id: "FR-009"
      description: "SHOULD support --schema flag to print expected schema for artifact type"
      testable: true
      acceptance_criteria: "Schema output shows all fields, types, required status, and valid enum values"

    - id: "FR-010"
      description: "SHOULD support --fix flag to auto-fix common issues"
      testable: true
      acceptance_criteria: "Fixable issues corrected in file, unfixable issues reported, changes summarized"

    - id: "FR-011"
      description: "MUST integrate validation into each phase's slash command template"
      testable: true
      acceptance_criteria: "Each autospec*.md template calls 'autospec artifact TYPE PATH' at end of phase"

    - id: "FR-012"
      description: "MUST return appropriate exit codes (0 for success, non-zero for validation failures)"
      testable: true
      acceptance_criteria: "Exit code 0 on valid, exit code 1 on validation errors, exit code 3 on invalid arguments"

    - id: "FR-013"
      description: "MUST provide comprehensive testdata fixtures in internal/validation/testdata/"
      testable: true
      acceptance_criteria: "Testdata directory contains organized fixtures for each artifact type and error category"

    - id: "FR-014"
      description: "Testdata MUST include valid golden files for each artifact type"
      testable: true
      acceptance_criteria: "Files at testdata/{spec,plan,tasks}/valid.yaml pass all validation checks"

    - id: "FR-015"
      description: "Testdata MUST include fixtures for missing required fields"
      testable: true
      acceptance_criteria: "Files at testdata/{spec,plan,tasks}/missing_*.yaml trigger missing field errors"

    - id: "FR-016"
      description: "Testdata MUST include fixtures for type mismatches"
      testable: true
      acceptance_criteria: "Files at testdata/{spec,plan,tasks}/wrong_type_*.yaml trigger type mismatch errors"

    - id: "FR-017"
      description: "Testdata MUST include fixtures for invalid enum values"
      testable: true
      acceptance_criteria: "Files at testdata/{spec,plan,tasks}/invalid_enum_*.yaml trigger enum validation errors"

    - id: "FR-018"
      description: "Testdata MUST include fixtures for cross-reference errors (tasks only)"
      testable: true
      acceptance_criteria: "Files at testdata/tasks/invalid_dep_*.yaml trigger dependency reference errors"

    - id: "FR-019"
      description: "Testdata MUST include fixtures for malformed YAML syntax"
      testable: true
      acceptance_criteria: "Files at testdata/common/malformed_*.yaml trigger YAML parse errors with line numbers"

    - id: "FR-020"
      description: "Each testdata fixture MUST include header comment documenting expected error"
      testable: true
      acceptance_criteria: "Each fixture file starts with comment block listing: error type, expected message pattern, relevant line numbers"

  non_functional:
    - id: "NFR-001"
      category: "performance"
      description: "Validation MUST complete in under 500ms for typical artifacts"
      measurable_target: "p99 validation time < 500ms for artifacts under 1000 lines"

    - id: "NFR-002"
      category: "usability"
      description: "Error messages MUST be actionable with clear hints for resolution"
      measurable_target: "Each error includes: location (line/field), description, and suggested fix"

    - id: "NFR-003"
      category: "reliability"
      description: "Validation MUST be idempotent - running multiple times produces same results"
      measurable_target: "Same input always produces identical output"

success_criteria:
  measurable_outcomes:
    - id: "SC-001"
      description: "Users can validate any artifact type with a single command"
      metric: "Command completion without additional steps"
      target: "One command validates one artifact completely"

    - id: "SC-002"
      description: "Validation errors provide enough context to fix issues without documentation lookup"
      metric: "Error message includes line number, field path, expected value type, and hint"
      target: "100% of errors include all four components"

    - id: "SC-003"
      description: "Auto-fix resolves common issues without user intervention"
      metric: "Percentage of fixable issues resolved by --fix flag"
      target: "100% of missing optional fields and formatting issues auto-fixed"

    - id: "SC-004"
      description: "All phase outputs are validated before workflow proceeds"
      metric: "Slash commands include validation step"
      target: "All 4 primary phase templates (specify, plan, tasks, implement) include validation"

    - id: "SC-005"
      description: "Validation catches structural errors early in workflow"
      metric: "Invalid artifacts detected before next phase"
      target: "0 invalid artifacts pass through to subsequent phases when validation enabled"

    - id: "SC-006"
      description: "Test fixtures cover all validation error categories"
      metric: "Number of error types with corresponding fixtures"
      target: "100% of error categories (missing field, wrong type, invalid enum, invalid ref, malformed YAML) have fixtures for each applicable artifact type"

    - id: "SC-007"
      description: "Test fixtures are table-driven and easy to extend"
      metric: "New validation rules can be tested by adding fixture file only"
      target: "Adding a new fixture requires no changes to test code (test discovery is automatic)"

key_entities:
  - name: "Artifact"
    description: "A YAML file produced by a workflow phase (spec, plan, or tasks)"
    attributes:
      - "type (spec, plan, tasks)"
      - "file path"
      - "content structure"
      - "validation status"

  - name: "Schema"
    description: "Definition of expected structure for an artifact type"
    attributes:
      - "artifact type"
      - "required fields"
      - "optional fields"
      - "field types and constraints"
      - "cross-reference rules"

  - name: "ValidationResult"
    description: "Outcome of validating an artifact against its schema"
    attributes:
      - "success/failure status"
      - "error list with line numbers"
      - "summary statistics"
      - "hints for resolution"

  - name: "AutoFix"
    description: "Automatic correction applied to an artifact"
    attributes:
      - "fix type (add optional field, normalize formatting)"
      - "location in file"
      - "before/after values"

  - name: "TestFixture"
    description: "A YAML file in testdata/ designed to trigger specific validation errors"
    attributes:
      - "artifact type (spec, plan, tasks, or common)"
      - "error category (missing_field, wrong_type, invalid_enum, invalid_dep, malformed)"
      - "expected error type and message pattern"
      - "relevant line numbers for error location"
      - "header comment documenting fixture purpose"

edge_cases:
  - scenario: "Empty file provided as artifact"
    expected_behavior: "Error indicating file is empty with hint to generate artifact first"

  - scenario: "File contains valid YAML but wrong artifact type structure"
    expected_behavior: "Error identifying missing top-level keys expected for artifact type"

  - scenario: "Circular dependencies in tasks.yaml"
    expected_behavior: "Error listing the cycle (e.g., T001 -> T002 -> T003 -> T001)"

  - scenario: "Task depends on itself"
    expected_behavior: "Error indicating self-reference with task ID and line number"

  - scenario: "--fix flag used on file with unfixable errors"
    expected_behavior: "Apply fixable changes, report unfixable errors, return non-zero exit"

  - scenario: "Artifact type argument missing"
    expected_behavior: "Error listing valid types (spec, plan, tasks) with usage example"

  - scenario: "Unknown artifact type provided"
    expected_behavior: "Error indicating invalid type with list of valid options"

  - scenario: "File path points to directory instead of file"
    expected_behavior: "Error indicating path is directory, suggest specific file path"

  - scenario: "--schema and --fix flags used together"
    expected_behavior: "--schema takes precedence, schema is printed, no fix attempted"

  - scenario: "--schema used with file path"
    expected_behavior: "Schema printed, file path ignored (schema is type-level, not file-specific)"

  - scenario: "Test fixture missing expected error header comment"
    expected_behavior: "Test framework warns about undocumented fixture but still runs validation"

  - scenario: "Test fixture has header comment but wrong error type in practice"
    expected_behavior: "Test fails with clear diff showing expected vs actual error"

assumptions:
  - "Schemas for spec.yaml, plan.yaml, and tasks.yaml are well-defined in specs/007-yaml-structured-output/contracts/yaml-schemas.yaml"
  - "YAML parsing uses the existing gopkg.in/yaml.v3 library already in the codebase"
  - "Validation follows existing patterns in internal/validation/ package"
  - "Slash command templates are in .autospec/commands/ directory"
  - "Auto-fix only addresses non-destructive changes (adding defaults, normalizing format)"
  - "Line numbers in error messages correspond to the YAML file as written, not parsed structure"
  - "Testdata fixtures live in internal/validation/testdata/ following Go conventions"
  - "Testdata directory structure: testdata/{spec,plan,tasks,common}/*.yaml"
  - "Each fixture file is self-documenting with header comments explaining expected behavior"

constraints:
  - "Must use existing Go validation patterns and libraries (go-playground/validator)"
  - "Must follow existing CLI architecture (Cobra commands in internal/cli/)"
  - "Must not break existing validation functions in internal/validation/"
  - "Exit codes must follow established conventions (0=success, 1=validation fail, 3=invalid args)"
  - "Performance must meet <500ms requirement for typical artifacts"

out_of_scope:
  - "Creating new artifact types beyond spec, plan, tasks"
  - "Validating markdown files or other non-YAML formats"
  - "Schema versioning or migration between schema versions"
  - "Remote/URL-based artifact validation"
  - "Interactive mode for fixing errors one-by-one"
  - "Custom user-defined schemas"
  - "Validation during file watch/auto-reload"

_meta:
  version: "1.0.0"
  generator: "autospec"
  generator_version: "dev (commit: 5498be8)"
  created: "2025-12-15T00:00:00Z"
  artifact_type: "spec"
