plan:
  branch: "102-e2e-mock-testing"
  created: "2026-01-16"
  spec_path: "specs/102-e2e-mock-testing/spec.yaml"

summary: |
  This plan addresses comprehensive E2E test coverage for the autospec CLI by extending
  the existing test infrastructure. The implementation creates mock-opencode.sh for OpenCode
  agent testing, enhances mock-claude.sh with additional slash command support, and adds
  systematic E2E tests for all 35+ CLI commands. The approach leverages the well-designed
  E2EEnv isolation framework and artifact generators already in place, focusing on filling
  coverage gaps while maintaining test determinism and sub-5-minute execution times through
  parallel test execution.

technical_context:
  language: "Go"
  framework: "Cobra CLI"
  primary_dependencies:
    - name: "github.com/spf13/cobra"
      version: "^1.8.0"
      purpose: "CLI command framework"
    - name: "github.com/stretchr/testify"
      version: "^1.9.0"
      purpose: "Test assertions and requirements"
  storage: "YAML files (specs/, .autospec/)"
  testing:
    framework: "Go testing package with testify assertions"
    approach: "E2E tests with isolated environments, mock CLI binaries, parallel execution"
  target_platform: "Linux, macOS (POSIX-compatible)"
  project_type: "cli"
  performance_goals: "Individual E2E tests <10s, full suite <5min with parallelization"
  constraints:
    - "No real API calls during tests"
    - "Tests must be deterministic with 100% pass rate on 10 consecutive runs"
    - "Cross-platform compatibility (Linux/macOS)"
    - "No network access required"
  scale_scope: "35+ CLI commands with comprehensive flag coverage"

constitution_check:
  constitution_path: ".autospec/memory/constitution.yaml"
  gates:
    - name: "Test-First Development"
      status: "PASS"
      notes: "Plan specifies test creation before implementation of new mock features"
    - name: "Idiomatic Go"
      status: "PASS"
      notes: "Tests use map-based table tests, errors wrapped with context, functions <40 lines"
    - name: "Performance Standards"
      status: "PASS"
      notes: "Individual tests <10s target, full suite <5min with t.Parallel()"
    - name: "Idempotent Operations"
      status: "PASS"
      notes: "Each test runs in isolated temp directory with no shared state"
    - name: "Test Safety"
      status: "PASS"
      notes: "E2EEnv provides complete isolation from real project files"
    - name: "Schema-Driven Artifacts"
      status: "PASS"
      notes: "All generated artifacts validated against schemas"

research_findings:
  decisions:
    - topic: "Mock script architecture for OpenCode"
      decision: "Create mock-opencode.sh mirroring mock-claude.sh structure"
      rationale: "Consistent architecture simplifies maintenance and allows reuse of MOCK_* env var patterns"
      alternatives_considered:
        - "Single unified mock script with agent parameter"
        - "Go-based mock binary instead of shell script"
    - topic: "Test organization for 35+ commands"
      decision: "Group tests by command category (workflow, stage, config, admin, worktree, dag, util)"
      rationale: "Matches existing CLI structure, enables selective test runs, improves maintainability"
      alternatives_considered:
        - "Single monolithic test file"
        - "One test file per command"
    - topic: "Exit code testing approach"
      decision: "Dedicated test file (exit_code_test.go) with scenarios for all 6 codes"
      rationale: "Exit codes are cross-cutting concern affecting all commands, deserve dedicated coverage"
      alternatives_considered:
        - "Spread exit code tests across command-specific files"
    - topic: "Mock network responses for doctor/update"
      decision: "Add MOCK_VERSION_INFO and MOCK_NETWORK_STATUS env vars to mock scripts"
      rationale: "Enables testing network-dependent commands without actual network calls"
      alternatives_considered:
        - "HTTP mock server"
        - "Skip network-dependent command testing"

data_model:
  entities:
    - name: "E2EEnv"
      description: "Extended test environment with OpenCode support"
      fields:
        - name: "mockOpencodePath"
          type: "string"
          description: "Path to mock-opencode.sh binary"
          constraints: "Must be executable"
        - name: "agentPreset"
          type: "string"
          description: "Current agent preset (claude or opencode)"
          constraints: "One of: claude, opencode"
      relationships:
        - target: "MockScript"
          type: "one-to-many"
          description: "E2EEnv manages multiple mock scripts"
    - name: "MockScript"
      description: "Shell script simulating CLI agent behavior"
      fields:
        - name: "MOCK_VERSION_INFO"
          type: "string"
          description: "Mock version data for update command"
          constraints: "JSON format with version info"
        - name: "MOCK_NETWORK_STATUS"
          type: "string"
          description: "Mock connectivity status for doctor command"
          constraints: "connected or disconnected"
      relationships:
        - target: "TestData"
          type: "one-to-many"
          description: "Mock scripts reference test data for artifact generation"
    - name: "CommandResult"
      description: "Result of running autospec command in isolated environment"
      fields:
        - name: "ExitCode"
          type: "int"
          description: "Process exit code (0-5)"
          constraints: "Must be 0-5 per documented exit codes"
        - name: "Stdout"
          type: "string"
          description: "Standard output capture"
          constraints: "None"
        - name: "Stderr"
          type: "string"
          description: "Standard error capture"
          constraints: "None"
        - name: "Duration"
          type: "time.Duration"
          description: "Command execution time"
          constraints: "Should be <10s for individual tests"
      relationships: []

api_contracts:
  endpoints: []

project_structure:
  documentation:
    - path: ".dev/tasks/102-e2e-mock-testing.md"
      description: "Manual testing plan for E2E test coverage feature"
  source_code:
    - path: "mocks/scripts/mock-opencode.sh"
      description: "New mock script for OpenCode agent testing"
    - path: "mocks/scripts/mock-claude.sh"
      description: "Enhanced mock with clarify/checklist/analyze support"
    - path: "internal/testutil/e2e.go"
      description: "Enhanced E2EEnv with OpenCode support and new helpers"
  tests:
    - path: "tests/e2e/*_test.go"
      description: "E2E test files organized by command category"
    - path: "tests/e2e/testdata/responses/*.yaml"
      description: "Test data fixtures for mock responses"

implementation_phases:
  - phase: 1
    name: "Safety and Mock Foundation"
    goal: "Establish safety verification tests and create mock-opencode.sh"
    deliverables:
      - "Safety verification tests for API key sanitization and PATH isolation"
      - "mock-opencode.sh script mirroring mock-claude.sh capabilities"
      - "E2EEnv extensions for OpenCode agent support"
      - "Basic OpenCode workflow test (US-002)"
  - phase: 2
    name: "Core Workflow Coverage"
    goal: "Comprehensive tests for run, implement, and stage commands"
    dependencies:
      - "Phase 1"
    deliverables:
      - "Run command tests with all flag combinations (-s, -p, -t, -i, -a)"
      - "Implement command tests for all execution modes (--phases, --tasks, --phase N)"
      - "Stage flag ordering property tests"
      - "Exit code verification tests for all 6 documented codes (0-5)"
  - phase: 3
    name: "Optional Stages and Global Flags"
    goal: "Test optional workflow stages and global flag behavior"
    dependencies:
      - "Phase 2"
    deliverables:
      - "Mock support for /autospec.clarify, /autospec.checklist, /autospec.analyze"
      - "Tests for clarify, checklist, analyze commands"
      - "Global flag tests (--max-retries, --agent, --config, --skip-preflight)"
      - "Error scenario tests with clear messages and exit codes"
  - phase: 4
    name: "Utility and Admin Commands"
    goal: "Complete coverage for utility, config, admin commands"
    dependencies:
      - "Phase 3"
    deliverables:
      - "Utility command tests (status, history, clean, view, ck)"
      - "Config command tests (init, show, set, get, toggle, keys, sync)"
      - "Admin command tests (commands check/info, completion, uninstall)"
      - "Doctor command with mock network status"
  - phase: 5
    name: "Worktree, DAG, and Finalization"
    goal: "Complete worktree/DAG tests and ensure 100% command coverage"
    dependencies:
      - "Phase 4"
    deliverables:
      - "Worktree command tests (create, list, remove, prune, setup, gen-script)"
      - "DAG command tests (run, status, logs, validate, watch, etc.)"
      - "Coverage audit to verify 100% command coverage"
      - "CI integration verification"
      - "Manual testing plan and changelog update"

open_questions:
  - question: "Should worktree tests create actual worktrees or mock the git operations?"
    context: "Creating real worktrees is slower but more realistic; mocking is faster but less thorough"
    proposed_resolution: "Create real worktrees in temp repo for accuracy; parallelize tests to maintain speed"
  - question: "How to handle interactive commands that require user input?"
    context: "Commands like init may prompt for input in certain scenarios"
    proposed_resolution: "Use --yes flag where available; add non-interactive mode flags if missing"
  - question: "Should property-based tests use rapid/gopter or simple permutation iteration?"
    context: "Property testing libraries add complexity but are more rigorous"
    proposed_resolution: "Use simple permutation iteration for flag order tests; complexity not justified for small flag sets"

_meta:
  version: "1.0.0"
  generator: "autospec"
  generator_version: "autospec 0.9.0"
  created: "2026-01-16T18:43:19Z"
  artifact_type: "plan"
